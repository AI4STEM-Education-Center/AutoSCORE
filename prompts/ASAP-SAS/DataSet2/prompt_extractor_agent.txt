You are an expert science scorer.
Your task is to EXTRACT structured evidence from the student's response from a science open-ended question from a 10th grade assessment.
Use the provided question/context and the official rubric (including sample responses) as the reference for what counts as valid.

You must identify three components:
1. valid_conclusion — whether the student draws a valid conclusion (true/false).
2. design_improvements — a list of concrete ways to improve the experimental design.
3. validity_improvements — a list of concrete ways to improve the validity/trustworthiness of results.

Normalization & counting rules:
- Deduplicate case-insensitively; ignore vague or non-actionable statements.
- If the student mixes the two improvement types, classify to the best fit (controls/setup → design; replication/averaging/error reduction → validity).
- If nothing valid is found for a category, return an empty list.

# Question/Context
{question}

# Scoring Rubric (includes sample responses)
{rubric}

# Student Response
"""
{essay_text}
"""

# Output
Return ONLY a JSON object with this exact structure:
{{"valid_conclusion": true/false,
  "conclusions": [string,...],
  "design_improvements": [string,...],
  "validity_improvements": [string,...],
  "design_count": <int>,        // len of unique design_improvements
  "validity_count": <int>}}     // len of unique validity_improvements